{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58282f3",
   "metadata": {},
   "source": [
    "# Week 2 - Challenge\n",
    "## LangChain Practice\n",
    "\n",
    "### Advanced Customer Service Agent with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d878b",
   "metadata": {},
   "source": [
    "> Deliverables\n",
    "\n",
    ">> 1. Implementation using LangChain Expression Language (LCEL) to build the agent.\n",
    ">> 2. Pydantic models for QueryAnalysis and ConversationSummary fully integrated into the chain.\n",
    ">> 3. Usage examples for each suggested test query, demonstrating the end-to-end functionality.\n",
    ">> 4. Results analysis. Include a screenshot or public link to a LangSmith trace for one of the complex queries to demonstrate successful tracing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e36538",
   "metadata": {},
   "source": [
    "#### Setup & API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "\n",
    "!pip install openai\n",
    "!pip install python-dotenv\n",
    "!pip install -qU \\\n",
    "  langchain-core \\\n",
    "  langchain-openai \\\n",
    "  langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f616705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import SystemMessagePromptTemplate,HumanMessagePromptTemplate,ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional, List\n",
    "import json, datetime\n",
    "\n",
    "# Load environment variables from .env file\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Define the OpenAI model to use\n",
    "\n",
    "openai_model = \"gpt-4o-mini\"\n",
    "\n",
    "# Initialize the OpenAI chat model\n",
    "\n",
    "llm = ChatOpenAI(model=openai_model,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bda05298",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"Neutral-Informative: Hello, I'd like to know if you have the new iPhone 15 in stock and how much shipping costs to Chicago\"\n",
    "    ,\"Urgent-Negative: This is an emergency! My order #TEC-2024-001 never arrived and I need that laptop for work tomorrow!\"\n",
    "    ,\"Satisfied-Positive: Thank you so much for the excellent service with my previous purchase. I want to buy gaming headphones\"\n",
    "    ,\"Frustrated-Technical: I can't configure the router I bought last week, I've tried everything and it doesn't work\"\n",
    "    ,\"Formal-Billing: Good morning, I need the receipt for my purchase from December 15th, order #TEC-2023-089\"\n",
    "    ,\"Warranty-Query: I bought a tablet 8 months ago and now it won't turn on, how do I use the warranty?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0dfb3f",
   "metadata": {},
   "source": [
    "#### Pydantic Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a83dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data model for the extracted information\n",
    "\n",
    "class ExtractedEntities(BaseModel):\n",
    "    product_name: Optional[str] = Field(None, description=\"The specific product mentioned by the user\")\n",
    "    order_number: Optional[str] = Field(None, description=\"The order number mentioned by the user\")\n",
    "    date_info: Optional[str] = Field(None, description=\"The date mentioned by the user (only if applicable)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9732d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query analysis model\n",
    "\n",
    "class QueryAnalysis(BaseModel):\n",
    "    \"\"\"Analyzes and classifies a customer query.\"\"\"\n",
    "    query_category: Literal[\"technical_support\",\"billing\",\"returns\",\"product_inquiry\",\"general_information\"]\n",
    "    urgency_level: Literal[\"low\",\"medium\",\"high\"]\n",
    "    customer_sentiment: Literal[\"positive\",\"neutral\",\"negative\"]\n",
    "    entities: ExtractedEntities  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template to analyze the user message and extract relevant information\n",
    "\n",
    "class ConversationSummary(BaseModel):\n",
    "    \"\"\"A structured summary of the customer service interaction.\"\"\"\n",
    "    timestamp: str\n",
    "    customer_id: str = \"auto_generated\"\n",
    "    conversation_summary: str = Field(description=\"A concise, one-sentence summary of the interaction.\")\n",
    "    query_category: str\n",
    "    customer_sentiment: str\n",
    "    urgency_level: str\n",
    "    mentioned_products: List[str]\n",
    "    extracted_information: dict\n",
    "    resolution_status: Literal[\"resolved\", \"pending\", \"escalated\"]\n",
    "    actions_taken: List[str] = Field(description=\"A list of actions the agent took or suggested.\")\n",
    "    follow_up_required: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c03261",
   "metadata": {},
   "source": [
    "#### 1° Component - Query Analysis & Classification\n",
    "\n",
    "Analyze the initial user query and extract key information into a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c111699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Model selected\n",
    "\n",
    "print(llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "624412f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Neutral-Informative: Hello, I'd like to know if you have the new iPhone 15 in stock and how much shipping costs to Chicago\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of the first query\n",
    "\n",
    "user_message = test_queries[0]\n",
    "user_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4af538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query_category\": \"product_inquiry\",\n",
      "  \"urgency_level\": \"medium\",\n",
      "  \"customer_sentiment\": \"neutral\",\n",
      "  \"entities\": {\n",
      "    \"product_name\": \"iPhone 15\",\n",
      "    \"order_number\": null,\n",
      "    \"date_info\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create a specific prompt for query analysis and classification\n",
    "\n",
    "system_prompt = (\n",
    "\"\"\"\n",
    "You are an intelligent assistant that analyzes customer service messages and classifies them with the following criteria:\n",
    "\n",
    "    1. Analyze the customer message and extract relevant information based on the pydantic model \"QueryAnalysis\".\n",
    "\n",
    "    2. Be accurate in your classification.\n",
    "\n",
    "    3. Respond ONLY with valid JSON structure\n",
    "\"\"\")\n",
    "\n",
    "user_prompt = (\n",
    "\"\"\"\n",
    "Analyze the customer message: {user_message}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "analysis_classification = ChatPromptTemplate.from_messages([\n",
    "system_prompt,\n",
    "user_prompt\n",
    "])\n",
    "\n",
    "# Create the chain\n",
    "\n",
    "analysis_chain = analysis_classification | llm.with_structured_output(QueryAnalysis)\n",
    "\n",
    "# Test the chain\n",
    "\n",
    "test_chain = analysis_chain.invoke({\"user_message\": user_message})\n",
    "\n",
    "print(test_chain.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d83e5c",
   "metadata": {},
   "source": [
    "#### 2° Component - Dynamic Response Generation\n",
    "\n",
    "Generate a context-aware, personalized response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca9cfc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_category_prompts = [\n",
    "    \"technical_support: should be empathetic, patient, and ask for relevant troubleshooting steps\",\n",
    "    \"billing: should be clear and polite, asking for details like invoice number or payment method\",\n",
    "    \"returns: should be understanding and explain the return process, asking for order number if needed\",\n",
    "    \"product_inquiry: should be helpful and informative, providing accurate product details\",\n",
    "    \"general_information: should be courteous and provide concise, relevant information or guidance\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cabf18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75927807",
   "metadata": {},
   "source": [
    "#### 3° Component - Conversation Summarization & Persistance\n",
    "\n",
    "Generate a structured summary of the entire interaction, ready for logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c056954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bb4b7ce",
   "metadata": {},
   "source": [
    "#### 4° LangSmith Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04c4fea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Urgent-Negative: This is an emergency! My order #TEC-2024-001 never arrived and I need that laptop for work tomorrow!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Query\n",
    "\n",
    "# Urgent-Negative: \n",
    "# \"This is an emergency! My order #TEC-2024-001 never arrived and I need that laptop for work tomorrow!\"\n",
    "\n",
    "test_queries[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
